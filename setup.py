#!/usr/bin/env python3
"""Javis è‡ªåŠ¨åŒ–é…ç½®è„šæœ¬

äº¤äº’å¼å¼•å¯¼ç”¨æˆ·å®Œæˆå®‰è£…å’Œé…ç½®ã€‚
"""
import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


# ANSI é¢œè‰²ä»£ç 
class Colors:
    """ç»ˆç«¯é¢œè‰²"""
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

    # ç¦ç”¨é¢œè‰²ï¼ˆåœ¨éç»ˆç«¯ç¯å¢ƒï¼‰
    DISABLED = False


def disable_colors():
    """ç¦ç”¨é¢œè‰²è¾“å‡º"""
    Colors.DISABLED = True


def c(color: str, text: str) -> str:
    """ä¸ºæ–‡æœ¬æ·»åŠ é¢œè‰²"""
    if Colors.DISABLED or not sys.stdout.isatty():
        return text
    return f"{color}{text}{Colors.ENDC}"


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print()
    print(c(Colors.OKCYAN, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"))
    print(c(Colors.OKCYAN, "â•‘                                                                   â•‘"))
    print(c(Colors.OKCYAN, "â•‘") + c(Colors.BOLD, "              Javis - å¸¦ RAG è®°å¿†çš„ä¸ªäºº AI åŠ©æ‰‹ç³»ç»Ÿ              ") + c(Colors.OKCYAN, "              â•‘"))
    print(c(Colors.OKCYAN, "â•‘") + c(Colors.OKGREEN, "                    è‡ªåŠ¨åŒ–é…ç½®å‘å¯¼                              ") + c(Colors.OKCYAN, "                    â•‘"))
    print(c(Colors.OKCYAN, "â•‘                                                                   â•‘"))
    print(c(Colors.OKCYAN, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"))
    print()


def print_step(num: int, total: int, title: str):
    """æ‰“å°æ­¥éª¤æ ‡é¢˜"""
    print()
    print(c(Colors.BOLD, f"â”Œâ”€ æ­¥éª¤ {num}/{total}: {title}"))
    print(c(Colors.OKCYAN, "â”‚") + " " + "â”€" * 60)
    print(c(Colors.OKCYAN, "â”‚"))


def print_step_end():
    """ç»“æŸæ­¥éª¤æ˜¾ç¤º"""
    print(c(Colors.OKCYAN, "â”‚"))
    print(c(Colors.OKCYAN, "â””") + " " + "â”€" * 62)
    print()


def print_success(text: str):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(c(Colors.OKCYAN, "â”‚ ") + c(Colors.OKGREEN, "âœ“") + f" {text}")


def print_error(text: str):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(c(Colors.OKCYAN, "â”‚ ") + c(Colors.FAIL, "âœ—") + f" {text}")


def print_info(text: str):
    """æ‰“å°æç¤ºä¿¡æ¯"""
    print(c(Colors.OKCYAN, "â”‚ ") + f"  {text}")


def print_input(prompt: str):
    """æ‰“å°è¾“å…¥æç¤º"""
    return input(c(Colors.OKCYAN, "â”‚ ") + c(Colors.WARNING, "â–¶") + f" {prompt}")


def print_option(num: int, text: str):
    """æ‰“å°é€‰é¡¹"""
    print(c(Colors.OKCYAN, f"â”‚   {num}. ") + text)


def print_header(text: str):
    """æ‰“å°å°æ ‡é¢˜"""
    print()
    print(c(Colors.OKCYAN, "â”‚ ") + c(Colors.BOLD, text))


def print_box(title: str, content: list, color=Colors.OKGREEN):
    """æ‰“å°ä¿¡æ¯æ¡†"""
    width = 60
    print()
    print(c(Colors.OKCYAN, "â”‚") + "â”Œ" + "â”€" * (width - 2) + "â”")
    print(c(Colors.OKCYAN, "â”‚") + c(color, f"â”‚ {title:^{width - 4}} â”‚"))
    print(c(Colors.OKCYAN, "â”‚") + "â”œ" + "â”€" * (width - 2) + "â”¤")
    for line in content:
        print(c(Colors.OKCYAN, "â”‚") + f"â”‚ {line:<{width - 4}} â”‚")
    print(c(Colors.OKCYAN, "â”‚") + "â””" + "â”€" * (width - 2) + "â”˜")
    print()


def show_progress(text: str, done=False):
    """æ˜¾ç¤ºè¿›åº¦æŒ‡ç¤º"""
    if not done:
        print(c(Colors.OKCYAN, "â”‚ ") + c(Colors.OKBLUE, "â—") + f" {text}...", end="\r")
    else:
        print(c(Colors.OKCYAN, "â”‚ ") + c(Colors.OKGREEN, "â—‰") + f" {text}")


def check_python_version() -> bool:
    """æ£€æŸ¥ Python ç‰ˆæœ¬"""
    total_steps = 6
    print_step(1, total_steps, "æ£€æŸ¥ Python ç‰ˆæœ¬")

    version = sys.version_info
    version_str = f"{version.major}.{version.minor}.{version.micro}"
    print_info(f"å½“å‰ Python ç‰ˆæœ¬: {c(Colors.BOLD, version_str)}")

    if version.major < 3 or (version.major == 3 and version.minor < 10):
        print_error("Python ç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬")
        print_info("è¯·å‡çº§ Python åé‡è¯•")
        print_step_end()
        return False

    print_success(f"Python {version_str} ç¬¦åˆè¦æ±‚")
    print_step_end()
    return True


def check_config_exists() -> bool:
    """æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨"""
    config_path = Path("config/servers.yaml")

    if config_path.exists():
        print()
        print(c(Colors.WARNING, "âš  æ£€æµ‹åˆ°å·²å­˜åœ¨é…ç½®æ–‡ä»¶ config/servers.yaml"))
        response = input(c(Colors.OKCYAN, "â”‚ ") + "æ˜¯å¦é‡æ–°é…ç½®ï¼Ÿ" + c(Colors.WARNING, "(y/N)") + ": ").strip().lower()
        return response == 'y'

    return True


def install_dependencies():
    """å®‰è£…ä¾èµ–"""
    total_steps = 6
    print_step(2, total_steps, "å®‰è£…ä¾èµ–åŒ…")

    show_progress("æ­£åœ¨å®‰è£…ä¾èµ–åŒ…")
    print()

    import subprocess
    result = subprocess.run(
        [sys.executable, "-m", "pip", "install", "-r", "requirements.txt"],
        capture_output=True,
        text=True
    )

    if result.returncode != 0:
        print_error("ä¾èµ–å®‰è£…å¤±è´¥")
        if result.stderr:
            print(c(Colors.OKCYAN, "â”‚ ") + result.stderr)
        print_step_end()
        return False

    print_success("ä¾èµ–åŒ…å®‰è£…å®Œæˆ")
    print_step_end()
    return True


def collect_llm_config() -> dict:
    """æ”¶é›† LLM é…ç½®"""
    total_steps = 6
    print_step(3, total_steps, "é…ç½® LLM æœåŠ¡å™¨")

    print_header("è¯·é€‰æ‹©ä½ çš„ LLM æœåŠ¡æä¾›å•†:")
    print_option("1", "OpenAI (GPT-4, GPT-4o)")
    print_option("2", "DeepSeek (æ·±åº¦æ±‚ç´¢)")
    print_option("3", "è±†åŒ… (å­—èŠ‚è·³åŠ¨)")
    print_option("4", "é€šä¹‰åƒé—® (é˜¿é‡Œäº‘)")
    print_option("5", "æ™ºè°± AI (ChatGLM)")
    print_option("6", "æœ¬åœ° Ollama")
    print_option("7", "è‡ªå®šä¹‰")

    choice = print_input("è¯·è¾“å…¥é€‰é¡¹ (1-7): ").strip()

    configs = {
        "1": {
            "name": "openai",
            "base_url": "https://api.openai.com/v1",
            "models": ["gpt-4o-mini", "gpt-4o"],
            "api_key_prompt": "è¯·è¾“å…¥ OpenAI API Key (sk-...): ",
            "emoji": "ğŸ¤–"
        },
        "2": {
            "name": "deepseek",
            "base_url": "https://api.deepseek.com/v1",
            "models": ["deepseek-chat", "deepseek-reasoner"],
            "api_key_prompt": "è¯·è¾“å…¥ DeepSeek API Key (sk-...): ",
            "emoji": "ğŸ”"
        },
        "3": {
            "name": "doubao",
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "models": ["doubao-pro-4k", "doubao-pro-32k"],
            "api_key_prompt": "è¯·è¾“å…¥è±†åŒ… API Key: ",
            "emoji": "ğŸ«˜"
        },
        "4": {
            "name": "qwen",
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "models": ["qwen-turbo", "qwen-plus"],
            "api_key_prompt": "è¯·è¾“å…¥é€šä¹‰åƒé—® API Key (sk-...): ",
            "emoji": "â˜ï¸"
        },
        "5": {
            "name": "zhipu",
            "base_url": "https://open.bigmodel.cn/api/paas/v4",
            "models": ["glm-4-flash", "glm-4-plus"],
            "api_key_prompt": "è¯·è¾“å…¥æ™ºè°± AI API Key: ",
            "emoji": "ğŸ§ "
        },
        "6": {
            "name": "ollama",
            "base_url": "http://localhost:11434/v1",
            "models": ["llama3", "qwen2"],
            "api_key_prompt": "Ollama é€šå¸¸ä¸éœ€è¦ API Keyï¼Œç›´æ¥å›è½¦: ",
            "api_key_default": "ollama",
            "emoji": "ğŸ¦™"
        },
        "7": {
            "name": "custom",
            "base_url": "",
            "models": [],
            "custom": True,
            "emoji": "âš™ï¸"
        }
    }

    config = configs.get(choice, configs["1"])

    # è‡ªå®šä¹‰é…ç½®
    if config.get("custom"):
        print_header("è¯·è¾“å…¥è‡ªå®šä¹‰é…ç½®:")
        base_url = print_input("API Base URL: ").strip()
        api_key = print_input("API Key: ").strip()
        models_input = print_input("æ¨¡å‹åˆ—è¡¨ (ç”¨é€—å·åˆ†éš”): ").strip()
        models = [m.strip() for m in models_input.split(",")]
        name = "custom"
        emoji = "âš™ï¸"
    else:
        base_url = config["base_url"]
        api_key = print_input(config["api_key_prompt"]).strip()
        if not api_key and config.get("api_key_default"):
            api_key = config["api_key_default"]
        models = config["models"]
        name = config["name"]
        emoji = config["emoji"]

    print()
    print_success(f"{emoji} å·²é…ç½®: {c(Colors.BOLD, name)}")
    print_info(f"  API åœ°å€: {c(Colors.OKBLUE, base_url)}")
    print_info(f"  æ¨¡å‹: {c(Colors.OKBLUE, ', '.join(models))}")

    print_step_end()
    return {
        "name": name,
        "base_url": base_url,
        "api_key": api_key,
        "models": models
    }


def collect_embedding_config(llm_config: dict) -> dict:
    """æ”¶é›†åµŒå…¥æœåŠ¡é…ç½®"""
    total_steps = 6
    print_step(4, total_steps, "é…ç½®è®°å¿†ç³»ç»Ÿ")

    print_header("è®°å¿†ç³»ç»Ÿéœ€è¦å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œè¯·é…ç½®åµŒå…¥æœåŠ¡:")
    print_option("1", "ä½¿ç”¨ä¸ LLM ç›¸åŒçš„ API (æ¨è)")
    print_option("2", "ä½¿ç”¨ä¸åŒçš„ API")
    print_option("3", c(Colors.FAIL, "ç¦ç”¨è®°å¿†ç³»ç»Ÿ"))

    choice = print_input("è¯·è¾“å…¥é€‰é¡¹ (1-3): ").strip()

    if choice == "3":
        print_info(c(Colors.WARNING, "è®°å¿†ç³»ç»Ÿå·²ç¦ç”¨ï¼ŒAI å°†æ— æ³•è®°ä½å¯¹è¯å†…å®¹"))
        print_step_end()
        return {"enabled": False}

    if choice == "1":
        # ä½¿ç”¨ç›¸åŒçš„ API
        provider_map = {
            "openai": "openai",
            "deepseek": "openai",
            "doubao": "openai",
            "qwen": "openai",
            "zhipu": "openai",
            "ollama": "local",
            "custom": "openai"
        }
        provider = provider_map.get(llm_config["name"], "openai")
        api_key = llm_config["api_key"]
        base_url = llm_config["base_url"].replace("/v1", "").replace("/chat", "")

        # é€‰æ‹©æ¨¡å‹
        if provider == "openai":
            print_header("é€‰æ‹©åµŒå…¥æ¨¡å‹:")
            print_option("1", "text-embedding-3-small" + c(Colors.OKGREEN, " (æ¨èï¼Œå¿«é€Ÿ)"))
            print_option("2", "text-embedding-3-large" + c(Colors.OKBLUE, " (æ›´é«˜ç²¾åº¦)"))
            print_info("æˆ–è€…ç›´æ¥è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§° (å¦‚: doubao-embedding)")
            model_choice = print_input("è¯·é€‰æ‹© (1-3) æˆ–è¾“å…¥æ¨¡å‹åç§°: ").strip()

            if model_choice == "2":
                model = "text-embedding-3-large"
            elif model_choice == "3":
                model = print_input("è¯·è¾“å…¥åµŒå…¥æ¨¡å‹åç§°: ").strip()
                while not model:
                    print_error("æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
                    model = print_input("è¯·è¾“å…¥åµŒå…¥æ¨¡å‹åç§°: ").strip()
            elif model_choice == "1" or not model_choice:
                model = "text-embedding-3-small"
            else:
                # ç”¨æˆ·ç›´æ¥è¾“å…¥äº†æ¨¡å‹åç§°
                model = model_choice
        else:
            print_info(f"é»˜è®¤ä½¿ç”¨ LLM æ¨¡å‹ä½œä¸ºåµŒå…¥æ¨¡å‹")
            model = llm_config["models"][0] if llm_config["models"] else "embedding"

            # ä¹Ÿå…è®¸è‡ªå®šä¹‰
            custom = print_input(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹ [{model}]ï¼Ÿç›´æ¥å›è½¦ç¡®è®¤ï¼Œæˆ–è¾“å…¥è‡ªå®šä¹‰: ").strip()
            if custom:
                model = custom

    else:
        # ä½¿ç”¨ä¸åŒçš„ API
        print_header("è¯·è¾“å…¥åµŒå…¥æœåŠ¡é…ç½®:")
        provider = print_input("æä¾›å•† (openai/gemini/local): ").strip() or "openai"
        api_key = print_input("API Key: ").strip()
        base_url = print_input("Base URL (å¯é€‰ï¼Œå›è½¦è·³è¿‡): ").strip() or ""

        # é€‰æ‹©æ¨¡å‹
        print_header("é€‰æ‹©åµŒå…¥æ¨¡å‹:")
        print_option("1", "text-embedding-3-small")
        print_option("2", "text-embedding-ada-002")
        print_option("3", "è‡ªå®šä¹‰æ¨¡å‹")
        model_choice = print_input("è¯·é€‰æ‹© (1-3): ").strip()

        if model_choice == "2":
            model = "text-embedding-ada-002"
        elif model_choice == "3":
            model = print_input("è¯·è¾“å…¥åµŒå…¥æ¨¡å‹åç§°: ").strip()
            while not model:
                print_error("æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
                model = print_input("è¯·è¾“å…¥åµŒå…¥æ¨¡å‹åç§°: ").strip()
        else:
            model = "text-embedding-3-small"

    print()
    print_success("è®°å¿†ç³»ç»Ÿé…ç½®å®Œæˆ")
    print_info(f"  æä¾›å•†: {c(Colors.OKBLUE, provider)}")
    print_info(f"  æ¨¡å‹: {c(Colors.OKBLUE, model)}")

    print_step_end()
    return {
        "enabled": True,
        "provider": provider,
        "model": model,
        "api_key": api_key,
        "base_url": base_url
    }


def create_config_file(llm_config: dict, embedding_config: dict):
    """åˆ›å»ºé…ç½®æ–‡ä»¶"""
    total_steps = 6
    print_step(5, total_steps, "åˆ›å»ºé…ç½®æ–‡ä»¶")

    show_progress("æ­£åœ¨ç”Ÿæˆé…ç½®æ–‡ä»¶")
    print()

    config_content = f"""# ============================================
# Javis é…ç½®æ–‡ä»¶ - è‡ªåŠ¨ç”Ÿæˆ
# ============================================

# --- LLM æœåŠ¡å™¨é…ç½® ---
servers:
  {llm_config['name']}:
    base_url: {llm_config['base_url']}
    api_key: {llm_config['api_key']}
    models:
"""

    for model in llm_config['models']:
        config_content += f"      - {model}\n"

    config_content += f"""
# --- è®°å¿†æœç´¢é…ç½® (RAG å‘é‡æ£€ç´¢) ---
memory_search:
  enabled: {str(embedding_config['enabled']).lower()}
  sources:
    - memory
    - sessions
  extra_paths: []
  memory_files_dir: "~/.javis/memory/{{user_id}}"  # ç”¨æˆ·è®°å¿†æ–‡ä»¶å­˜å‚¨ç›®å½•

  # Embedding Provider
  provider: {embedding_config.get('provider', 'openai')}
  model: {embedding_config.get('model', 'text-embedding-3-small')}
  fallback: none

  # è¿œç¨‹ API é…ç½®
  remote:
    api_key: {embedding_config.get('api_key', llm_config['api_key'])}
"""

    if embedding_config.get('base_url'):
        config_content += f"    base_url: {embedding_config['base_url']}\n"
    else:
        config_content += f"    base_url: {llm_config['base_url'].replace('/v1', '')}\n"

    config_content += """    gemini_api_key: ""
    batch:
      enabled: true
      wait: true
      concurrency: 2
      timeout_minutes: 60

  # æœ¬åœ°å‘é‡åŒ–é…ç½®
  local:
    model_path: ""
    model_cache_dir: ""
    device: cpu

  # å­˜å‚¨é…ç½®
  store:
    path: "~/.javis/memory/{user_id}/memory.sqlite"
    vector:
      enabled: true
      extension_path: ""

  # åˆ†å—é…ç½®
  chunking:
    tokens: 400
    overlap: 80

  # åŒæ­¥é…ç½®
  sync:
    on_session_start: true
    on_search: false
    watch: true
    watch_debounce_ms: 1500
    interval_minutes: 0

  # æ£€ç´¢é…ç½®
  query:
    max_results: 6
    min_score: 0.5
    hybrid:
      enabled: true
      vector_weight: 0.7
      text_weight: 0.3
      candidate_multiplier: 4

  # ç¼“å­˜é…ç½®
  cache:
    enabled: true
    max_entries: 10000

# --- æ•°æ®åº“ ---
database:
  url: sqlite+aiosqlite:///./javis.db

# --- ç¼“å­˜ ---
cache:
  enabled: true

# --- æ—¥å¿— ---
logging:
  level: INFO
  slow_request_threshold: 5.0
"""

    config_path = Path("config/servers.yaml")
    config_path.write_text(config_content)

    print_success(f"é…ç½®æ–‡ä»¶å·²åˆ›å»º: {c(Colors.OKBLUE, config_path)}")
    print_step_end()


async def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    total_steps = 6
    print_step(6, total_steps, "åˆå§‹åŒ–æ•°æ®åº“")

    show_progress("æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“")
    print()

    try:
        from database.session import init_db, get_db_session, close_db
        from database.repository import UserRepository
        from services.auth import AuthService

        await init_db()
        print_success("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

        # æ”¶é›†ç”¨æˆ·å
        print_header("åˆ›å»ºé»˜è®¤ç”¨æˆ·")
        username = print_input("è¯·è¾“å…¥ç”¨æˆ·å (ç›´æ¥å›è½¦ä½¿ç”¨ 'default_user'): ").strip()
        if not username:
            username = "default_user"

        async for session in get_db_session():
            user = await UserRepository.get_or_create(
                session,
                name=username,
                email=None
            )
            await session.commit()

            api_key = await AuthService.create_api_key(
                session,
                user_id=user.id,
                name="Default API Key",
                daily_limit=10000,
                expires_days=365
            )
            await session.commit()

            print_success(f"ç”¨æˆ· '{username}' å’Œ API Key åˆ›å»ºå®Œæˆ")
            break

        await close_db()

        print_step_end()

        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        print_box("åˆå§‹åŒ–å®Œæˆï¼", [
            f"ç”¨æˆ·ID: {user.id}",
            f"ç”¨æˆ·å: {user.name}",
            f"è®°å¿†ç›®å½•: ~/.javis/memory/{user.id}/",
            "",
            "API Key (è¯·å¦¥å–„ä¿ç®¡):",
            f"{c(Colors.BOLD, c(Colors.OKGREEN, api_key.key))}"
        ])

        return api_key.key

    except Exception as e:
        print_error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        print_step_end()
        return None


def print_completion_guide(api_key: str):
    """æ‰“å°å®Œæˆåçš„ä½¿ç”¨æŒ‡å—"""
    print()
    print(c(Colors.OKCYAN, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"))
    print(c(Colors.OKCYAN, "â•‘") + c(Colors.BOLD, "                    ğŸ‰ é…ç½®å®Œæˆï¼ä¸‹ä¸€æ­¥                              ") + c(Colors.OKCYAN, "                    â•‘"))
    print(c(Colors.OKCYAN, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"))
    print()
    print(c(Colors.OKGREEN, "1ï¸âƒ£  å¯åŠ¨æœåŠ¡:"))
    print("   " + c(Colors.OKBLUE, "python run.py"))
    print()
    print(c(Colors.OKGREEN, "2ï¸âƒ£  æµ‹è¯•èŠå¤©:"))
    print(f"   curl -X POST http://localhost:8000/v1/chat/completions \\")
    print(f"     -H \"Content-Type: application/json\" \\")
    print(f"     -H \"Authorization: Bearer {c(Colors.OKGREEN, api_key[:20])}...\" \\")
    print(f"     -d '{{\"model\":\"gpt-4o-mini\",\"messages\":[{{\"role\":\"user\",\"content\":\"ä½ å¥½\"}}]}}'")
    print()
    print(c(Colors.OKGREEN, "3ï¸âƒ£  è®¿é—® API æ–‡æ¡£:"))
    print("   " + c(Colors.OKBLUE, "http://localhost:8000/docs"))
    print()
    print(c(Colors.OKCYAN, "â”€" * 69))
    print()


def main():
    """ä¸»å‡½æ•°"""
    print_banner()

    # æ£€æµ‹ Windows ç¯å¢ƒï¼Œç¦ç”¨é¢œè‰²
    if sys.platform == "win32":
        try:
            import colorama
            colorama.init()
        except ImportError:
            disable_colors()

    try:
        # æ£€æŸ¥ Python ç‰ˆæœ¬
        if not check_python_version():
            sys.exit(1)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°é…ç½®
        if not check_config_exists():
            print("é…ç½®å·²å­˜åœ¨ï¼Œå¦‚éœ€é‡æ–°é…ç½®è¯·åˆ é™¤ config/servers.yaml")
            print()
            print("ç»§ç»­ä½¿ç”¨ç°æœ‰é…ç½®è¿›è¡Œåˆå§‹åŒ–ï¼Ÿ(y/N): ", end="")
            if input().strip().lower() != 'y':
                print("é…ç½®å·²å–æ¶ˆ")
                sys.exit(0)

            # ç›´æ¥åˆå§‹åŒ–æ•°æ®åº“
            api_key = asyncio.run(init_database())
            if api_key:
                print_completion_guide(api_key)
            sys.exit(0)

        # å®‰è£…ä¾èµ–
        if not install_dependencies():
            sys.exit(1)

        # æ”¶é›†é…ç½®
        llm_config = collect_llm_config()
        embedding_config = collect_embedding_config(llm_config)

        # åˆ›å»ºé…ç½®æ–‡ä»¶
        create_config_file(llm_config, embedding_config)

        # åˆå§‹åŒ–æ•°æ®åº“
        api_key = asyncio.run(init_database())

        if api_key:
            print_completion_guide(api_key)

        print(c(Colors.OKGREEN, "âœ“ é…ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œ '") + c(Colors.OKBLUE, "python run.py") + c(Colors.OKGREEN, "' å¯åŠ¨æœåŠ¡"))
        print()

    except KeyboardInterrupt:
        print()
        print()
        print(c(Colors.WARNING, "âš  é…ç½®å·²å–æ¶ˆ"))
        sys.exit(1)
    except Exception as e:
        print()
        print(c(Colors.FAIL, f"âœ— é…ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"))
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
